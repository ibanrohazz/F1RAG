{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHOp9Ls0FwZ3"
   },
   "source": [
    "# Formula 1 Knowledge Base with RAG Architecture\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) system for answering Formula 1 questions. RAG combines the power of:\n",
    "\n",
    "1. **Retrieval**: Finding relevant information from a knowledge base\n",
    "2. **Generation**: Producing natural answers based on retrieved information\n",
    "\n",
    "## GitHub\n",
    "\n",
    "To view a sizably larger (and somewhat less complete) version of this model please feel free to check out my github repo https://github.com/ibanrohazz/F1RAG \n",
    "\n",
    "## How This System Works\n",
    "\n",
    "1. We load Formula 1 race data spanning from 1950 to 2024 from https://www.kaggle.com/datasets/rohanrao/formula-1-world-championship-1950-2020 \n",
    "2. Create a structured knowledge base of racing facts\n",
    "3. Embed these facts using transformer models\n",
    "4. Build a semantic search index with FAISS\n",
    "5. Implement a chatbot that combines:\n",
    "   - Semantic search retrieval\n",
    "   - Knowledge-based answer generation\n",
    "   - Context-aware follow-up question handling\n",
    "\n",
    "Let's start by loading the Formula 1 dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH61pGc5GVPa",
    "outputId": "08432e86-f48e-4077-c639-f52a50c77c22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.6.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.51.3)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.67.1)\n",
      "Requirement already satisfied: kagglehub in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.12)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mroja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: C:\\Users\\mroja\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install all necessary libraries\n",
    "%pip install pandas torch scikit-learn transformers faiss-cpu tqdm kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-8CuYa3HbHU",
    "outputId": "edc022b4-8b14-4479-ee49-fe9a4919d489"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mroja\\AppData\\Local\\Temp\\ipykernel_37128\\2064014931.py:6: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  races = kagglehub.load_dataset(\n",
      "C:\\Users\\mroja\\AppData\\Local\\Temp\\ipykernel_37128\\2064014931.py:11: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  drivers = kagglehub.load_dataset(\n",
      "C:\\Users\\mroja\\AppData\\Local\\Temp\\ipykernel_37128\\2064014931.py:16: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  results = kagglehub.load_dataset(\n",
      "C:\\Users\\mroja\\AppData\\Local\\Temp\\ipykernel_37128\\2064014931.py:21: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
      "  constructors = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1125 races, 861 drivers, 26759 results.\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import pandas as pd\n",
    "\n",
    "# Load all necessary files into separate DataFrames\n",
    "races = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"rohanrao/formula-1-world-championship-1950-2020\",\n",
    "    \"races.csv\"\n",
    ")\n",
    "drivers = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"rohanrao/formula-1-world-championship-1950-2020\",\n",
    "    \"drivers.csv\"\n",
    ")\n",
    "results = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"rohanrao/formula-1-world-championship-1950-2020\",\n",
    "    \"results.csv\"\n",
    ")\n",
    "constructors = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"rohanrao/formula-1-world-championship-1950-2020\",\n",
    "    \"constructors.csv\"\n",
    ")\n",
    "\n",
    "# Now you can access the data directly:\n",
    "print(\"Loaded:\", len(races), \"races,\", len(drivers), \"drivers,\", len(results), \"results.\")\n",
    "\n",
    "# If you want to combine them into a single DataFrame:\n",
    "# Create a 'table' column for each DataFrame\n",
    "races['table'] = 'races'\n",
    "drivers['table'] = 'drivers'\n",
    "results['table'] = 'results'\n",
    "constructors['table'] = 'constructors'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "f1_df = pd.concat([races, drivers, results, constructors], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoXhWvsHFe8j",
    "outputId": "5c2927c0-d698-4765-8172-4458e1ddd821"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 1125 races, 861 drivers, 26759 results.\n"
     ]
    }
   ],
   "source": [
    "# Assuming your new DataFrame is called 'f1_df'\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "\n",
    "# No need to load from CSV anymore\n",
    "# races = pd.read_csv('races.csv')\n",
    "# drivers = pd.read_csv('drivers.csv')\n",
    "# results = pd.read_csv('results.csv')\n",
    "# constructors = pd.read_csv('constructors.csv')\n",
    "\n",
    "# Access data directly from the new DataFrame\n",
    "races = f1_df[f1_df['table'] == 'races']  # Assuming 'table' column identifies data type\n",
    "drivers = f1_df[f1_df['table'] == 'drivers']\n",
    "results = f1_df[f1_df['table'] == 'results']\n",
    "constructors = f1_df[f1_df['table'] == 'constructors']\n",
    "\n",
    "print(\"Loaded:\", len(races), \"races,\", len(drivers), \"drivers,\", len(results), \"results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hy4Z1o01Fx44"
   },
   "source": [
    "# Building the Formula 1 Knowledge Base\n",
    "\n",
    "A knowledge base is the foundation of any RAG system. For our Formula 1 assistant, we'll create a structured repository of racing facts that can be efficiently searched.\n",
    "\n",
    "## Process:\n",
    "1. Merge race results with driver and constructor data\n",
    "2. Extract only winning results (position = 1)\n",
    "3. Format each win as a natural language fact\n",
    "4. These facts will become our searchable knowledge units\n",
    "\n",
    "This approach creates a clean, structured knowledge base that's both human-readable and machine-searchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "zB24yq19FmeM",
    "outputId": "8379f627-b53d-415a-9d50-3df08e839b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raceId_f1data', 'year_results', 'round_results', 'circuitId_results', 'name_results', 'date_results', 'time_results', 'url_results', 'fp1_date_results', 'fp1_time_results', 'fp2_date_results', 'fp2_time_results', 'fp3_date_results', 'fp3_time_results', 'quali_date_results', 'quali_time_results', 'sprint_date_results', 'sprint_time_results', 'table_results', 'driverId_results', 'driverRef_results', 'number_results', 'code_results', 'forename_results', 'surname_results', 'dob_results', 'nationality_results', 'resultId_results', 'constructorId_results', 'grid_results', 'position_results', 'positionText_results', 'positionOrder_results', 'points_results', 'laps_results', 'milliseconds_results', 'fastestLap_results', 'rank_results', 'fastestLapTime_results', 'fastestLapSpeed_results', 'statusId_results', 'constructorRef_results', 'year_races', 'round_races', 'circuitId_races', 'name_races', 'date_races', 'time_races', 'url_races', 'fp1_date_races', 'fp1_time_races', 'fp2_date_races', 'fp2_time_races', 'fp3_date_races', 'fp3_time_races', 'quali_date_races', 'quali_time_races', 'sprint_date_races', 'sprint_time_races', 'table_races', 'driverId_races', 'driverRef_races', 'number_races', 'code_races', 'forename_races', 'surname_races', 'dob_races', 'nationality_races', 'resultId_races', 'constructorId_races', 'grid_races', 'position_races', 'positionText_races', 'positionOrder_races', 'points_races', 'laps_races', 'milliseconds_races', 'fastestLap_races', 'rank_races', 'fastestLapTime_races', 'fastestLapSpeed_races', 'statusId_races', 'constructorRef_races', 'raceId_drivers', 'year_f1data', 'round_f1data', 'circuitId_f1data', 'name_f1data', 'date_f1data', 'time_f1data', 'url_f1data', 'fp1_date_f1data', 'fp1_time_f1data', 'fp2_date_f1data', 'fp2_time_f1data', 'fp3_date_f1data', 'fp3_time_f1data', 'quali_date_f1data', 'quali_time_f1data', 'sprint_date_f1data', 'sprint_time_f1data', 'table_f1data', 'driverId_f1data', 'driverRef_f1data', 'number_f1data', 'code_f1data', 'forename_f1data', 'surname_f1data', 'dob_f1data', 'nationality_f1data', 'resultId_f1data', 'constructorId_f1data', 'grid_f1data', 'position_f1data', 'positionText_f1data', 'positionOrder_f1data', 'points_f1data', 'laps_f1data', 'milliseconds_f1data', 'fastestLap_f1data', 'rank_f1data', 'fastestLapTime_f1data', 'fastestLapSpeed_f1data', 'statusId_f1data', 'constructorRef_f1data', 'raceId', 'year_constructors', 'round_constructors', 'circuitId_constructors', 'name_constructors', 'date_constructors', 'time_constructors', 'url_constructors', 'fp1_date_constructors', 'fp1_time_constructors', 'fp2_date_constructors', 'fp2_time_constructors', 'fp3_date_constructors', 'fp3_time_constructors', 'quali_date_constructors', 'quali_time_constructors', 'sprint_date_constructors', 'sprint_time_constructors', 'table_constructors', 'driverId_constructors', 'driverRef_constructors', 'number_constructors', 'code_constructors', 'forename_constructors', 'surname_constructors', 'dob_constructors', 'nationality_constructors', 'resultId_constructors', 'constructorId_constructors', 'grid_constructors', 'position_constructors', 'positionText_constructors', 'positionOrder_constructors', 'points_constructors', 'laps_constructors', 'milliseconds_constructors', 'fastestLap_constructors', 'rank_constructors', 'fastestLapTime_constructors', 'fastestLapSpeed_constructors', 'statusId_constructors', 'constructorRef_constructors']\n",
      "Sample Fact: In 2008, Lewis Hamilton won the Australian Grand Prix driving for McLaren.\n"
     ]
    }
   ],
   "source": [
    "f1_data = results.merge(races, on='raceId', suffixes=('_results', '_races'))\n",
    "f1_data = f1_data.merge(drivers, left_on='driverId_results', right_on='driverId', suffixes=('_f1data', '_drivers'))\n",
    "f1_data = f1_data.merge(constructors, left_on='constructorId_results', right_on='constructorId', suffixes=('_f1data', '_constructors'))\n",
    "\n",
    "# Only winning results\n",
    "winners = f1_data[f1_data['positionOrder_results'] == 1].copy()\n",
    "\n",
    "# Inspect columns to determine correct driver and constructor column names\n",
    "print(winners.columns.tolist())\n",
    "\n",
    "# Use the correct columns for driver names (update as needed after inspecting columns)\n",
    "winners.loc[:, 'fact'] = winners.apply(\n",
    "    lambda row: f\"In {row['year_races']:.0f}, {row['forename_f1data']} {row['surname_f1data']} won the {row['name_races']} driving for {row['name_constructors']}.\",\n",
    "    axis=1\n",
    ")\n",
    "f1_facts = winners[['fact']].reset_index(drop=True)\n",
    "\n",
    "print(\"Sample Fact:\", f1_facts.iloc[0]['fact'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t07ZLcGYF1Jf"
   },
   "source": [
    "# Embedding the Knowledge Base\n",
    "\n",
    "To make our knowledge searchable, we need to convert text facts into vector representations (embeddings) that capture semantic meaning.\n",
    "\n",
    "## The Embedding Process:\n",
    "1. Load a pre-trained language model optimized for semantic similarity\n",
    "2. Transform each Formula 1 fact into a dense vector (embedding)\n",
    "3. These vectors position similar facts closer together in vector space\n",
    "4. When a user asks a question, we'll embed it using the same model and find the closest facts\n",
    "\n",
    "The embedding model we're using is specifically trained to preserve semantic relationships, allowing us to find relevant information even when phrasing differs between questions and facts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fposwmHpFoYi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:03<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded 1128 facts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Embedding function\n",
    "def compute_embeddings(texts, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert(**inputs)\n",
    "            embeddings = outputs.last_hidden_state[:, 0]\n",
    "            embeddings = F.normalize(embeddings, dim=1)\n",
    "            all_embeddings.append(embeddings.cpu())\n",
    "    return torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "# Compute\n",
    "fact_embeddings = compute_embeddings(f1_facts['fact'].tolist())\n",
    "print(\"Embedded\", fact_embeddings.shape[0], \"facts.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFwdKq9CF3yA"
   },
   "source": [
    "# Designing an Efficient Retrieval System\n",
    "\n",
    "Effective retrieval is critical for any question-answering system. Our retrieval component uses FAISS (Facebook AI Similarity Search) for high-performance vector similarity search.\n",
    "\n",
    "## Enhanced Retrieval Features:\n",
    "1. **Metadata filtering** - Quickly narrow down search space using years, circuits, drivers\n",
    "2. **Query intent analysis** - Understand what type of information the user is looking for\n",
    "3. **Entity recognition** - Identify key F1 entities mentioned in questions\n",
    "4. **Hybrid search** - Combine exact metadata matching with semantic similarity\n",
    "\n",
    "This multi-stage approach balances precision and recall, enabling both exact matches for specific queries and more flexible semantic matching for exploratory questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8zXqb9s6FqA0"
   },
   "outputs": [],
   "source": [
    "class F1FAISSRetriever:\n",
    "    def __init__(self, facts, embeddings):\n",
    "        self.facts = facts\n",
    "        dim = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(dim)\n",
    "        self.index.add(embeddings.numpy())\n",
    "        \n",
    "        # Create dictionaries for metadata filtering\n",
    "        self.facts_by_year = {}\n",
    "        self.facts_by_circuit = {}\n",
    "        self.facts_by_driver = {}\n",
    "        self.facts_by_constructor = {}\n",
    "        \n",
    "        # Extract metadata from facts for faster filtering\n",
    "        import re\n",
    "        for i, fact in enumerate(facts):\n",
    "            # Extract year\n",
    "            year_match = re.search(r\"In (\\d{4}),\", fact)\n",
    "            if year_match:\n",
    "                year = year_match.group(1)\n",
    "                if year not in self.facts_by_year:\n",
    "                    self.facts_by_year[year] = []\n",
    "                self.facts_by_year[year].append(i)\n",
    "            \n",
    "            # Extract circuit names\n",
    "            circuits = [\"Monaco\", \"Silverstone\", \"Abu Dhabi\", \"Bahrain\", \"Malaysia\", \n",
    "                       \"Las Vegas\", \"Qatar\", \"São Paulo\", \"Mexico City\", \"Austrian\", \n",
    "                       \"German\", \"South African\", \"Hungarian\", \"Italian\", \"British\", \n",
    "                       \"Belgian\", \"Spanish\", \"Canadian\", \"Australian\", \"Japanese\", \"French\"]\n",
    "            for circuit in circuits:\n",
    "                if circuit in fact:\n",
    "                    if circuit not in self.facts_by_circuit:\n",
    "                        self.facts_by_circuit[circuit] = []\n",
    "                    self.facts_by_circuit[circuit].append(i)\n",
    "            \n",
    "            # Extract driver names - simple approach, could be improved\n",
    "            driver_match = re.search(r\", ([A-Za-z]+ [A-Za-z]+) won the\", fact)\n",
    "            if driver_match:\n",
    "                driver = driver_match.group(1)\n",
    "                if driver not in self.facts_by_driver:\n",
    "                    self.facts_by_driver[driver] = []\n",
    "                self.facts_by_driver[driver].append(i)\n",
    "            \n",
    "            # Extract constructor names\n",
    "            constructor_match = re.search(r\"driving for ([A-Za-z]+)\", fact)\n",
    "            if constructor_match:\n",
    "                constructor = constructor_match.group(1)\n",
    "                if constructor not in self.facts_by_constructor:\n",
    "                    self.facts_by_constructor[constructor] = []\n",
    "                self.facts_by_constructor[constructor].append(i)\n",
    "\n",
    "    def analyze_query(self, query):\n",
    "        \"\"\"Analyze the query to understand user intent and extract key entities\"\"\"\n",
    "        import re\n",
    "        \n",
    "        entities = {\n",
    "            'year': None,\n",
    "            'circuit': None,\n",
    "            'driver': None,\n",
    "            'constructor': None,\n",
    "            'query_type': 'general'  # default query type\n",
    "        }\n",
    "        \n",
    "        # Detect year mentions\n",
    "        year_match = re.search(r\"\\b(19|20)\\d{2}\\b\", query)\n",
    "        if year_match:\n",
    "            entities['year'] = year_match.group(0)\n",
    "        \n",
    "        # Detect circuit mentions\n",
    "        circuits = [\"Monaco\", \"Silverstone\", \"Abu Dhabi\", \"Bahrain\", \"Malaysia\", \n",
    "                   \"Las Vegas\", \"Qatar\", \"São Paulo\", \"Mexico City\", \"Austrian\", \n",
    "                   \"German\", \"South African\", \"Hungarian\", \"Italian\", \"British\", \n",
    "                   \"Belgian\", \"Spanish\", \"Canadian\", \"Australian\", \"Japanese\", \"French\"]\n",
    "        for circuit in circuits:\n",
    "            if circuit.lower() in query.lower():\n",
    "                entities['circuit'] = circuit\n",
    "                break\n",
    "        \n",
    "        # Detect query types\n",
    "        if any(word in query.lower() for word in ['win', 'won', 'winner', 'victory']):\n",
    "            entities['query_type'] = 'win'\n",
    "        elif any(word in query.lower() for word in ['champion', 'championship']):\n",
    "            entities['query_type'] = 'championship'\n",
    "        elif 'constructor' in query.lower() or 'team' in query.lower():\n",
    "            entities['query_type'] = 'constructor'\n",
    "        \n",
    "        # Find drivers in query (simplistic approach)\n",
    "        for driver, indices in self.facts_by_driver.items():\n",
    "            if driver.lower() in query.lower():\n",
    "                entities['driver'] = driver\n",
    "                break\n",
    "        \n",
    "        # Find constructors in query\n",
    "        for constructor, indices in self.facts_by_constructor.items():\n",
    "            if constructor.lower() in query.lower():\n",
    "                entities['constructor'] = constructor\n",
    "                break\n",
    "        \n",
    "        return entities\n",
    "\n",
    "    def retrieve(self, query, k=5):\n",
    "        \"\"\"Enhanced retrieval with metadata filtering and query analysis\"\"\"\n",
    "        # Analyze query to understand intent\n",
    "        query_analysis = self.analyze_query(query)\n",
    "        \n",
    "        # Start with all facts\n",
    "        candidate_indices = set(range(len(self.facts)))\n",
    "        filtered_facts = self.facts\n",
    "        filtered_indices = list(candidate_indices)\n",
    "        \n",
    "        # Apply metadata filters based on query analysis\n",
    "        if query_analysis['year'] and query_analysis['year'] in self.facts_by_year:\n",
    "            year_indices = set(self.facts_by_year[query_analysis['year']])\n",
    "            candidate_indices = candidate_indices.intersection(year_indices)\n",
    "        \n",
    "        if query_analysis['circuit'] and query_analysis['circuit'] in self.facts_by_circuit:\n",
    "            circuit_indices = set(self.facts_by_circuit[query_analysis['circuit']])\n",
    "            candidate_indices = candidate_indices.intersection(circuit_indices)\n",
    "            \n",
    "        if query_analysis['driver'] and query_analysis['driver'] in self.facts_by_driver:\n",
    "            driver_indices = set(self.facts_by_driver[query_analysis['driver']])\n",
    "            candidate_indices = candidate_indices.intersection(driver_indices)\n",
    "            \n",
    "        if query_analysis['constructor'] and query_analysis['constructor'] in self.facts_by_constructor:\n",
    "            constructor_indices = set(self.facts_by_constructor[query_analysis['constructor']])\n",
    "            candidate_indices = candidate_indices.intersection(constructor_indices)\n",
    "        \n",
    "        # If we have filtered indices, use them\n",
    "        if candidate_indices:\n",
    "            filtered_indices = list(candidate_indices)\n",
    "            filtered_facts = [self.facts[i] for i in filtered_indices]\n",
    "        \n",
    "        # If filtering results in no facts, fall back to all\n",
    "        if not filtered_facts:\n",
    "            filtered_facts = self.facts\n",
    "            filtered_indices = list(range(len(self.facts)))\n",
    "        \n",
    "        # Embed query and filtered facts\n",
    "        inputs = tokenizer(filtered_facts, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert(**inputs)\n",
    "            fact_embs = outputs.last_hidden_state[:, 0]\n",
    "            fact_embs = F.normalize(fact_embs, dim=1)\n",
    "        \n",
    "        # Embed query\n",
    "        q_inputs = tokenizer(query, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            q_output = bert(**q_inputs)\n",
    "            query_emb = q_output.last_hidden_state[:, 0]\n",
    "            query_emb = F.normalize(query_emb, dim=1)\n",
    "        \n",
    "        # Compute similarity and get top-k results\n",
    "        sims = torch.matmul(query_emb, fact_embs.T).squeeze(0)\n",
    "        topk = torch.topk(sims, min(k, len(filtered_facts)))\n",
    "        \n",
    "        # Map back to original indices and return with scores\n",
    "        results = []\n",
    "        for rank, idx in enumerate(topk.indices):\n",
    "            original_idx = filtered_indices[idx]\n",
    "            score = float(sims[idx])\n",
    "            results.append((self.facts[original_idx], score, query_analysis))\n",
    "        \n",
    "        return results\n",
    "\n",
    "retriever = F1FAISSRetriever(f1_facts['fact'].tolist(), fact_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoKrYm-2F5k9"
   },
   "source": [
    "# Conversational Formula 1 Assistant\n",
    "\n",
    "The final component of our system is a conversational interface that ties everything together. This chatbot combines:\n",
    "\n",
    "## Key Capabilities:\n",
    "1. **Specialized handlers** for common question types:\n",
    "   - Driver comparisons and statistics\n",
    "   - Constructor/team performance analysis\n",
    "   - Championship season summaries\n",
    "   - Race-specific results\n",
    "\n",
    "2. **Context maintenance** for follow-up questions:\n",
    "   - Remembers previous questions and retrieved facts\n",
    "   - Understands references like \"How about in 2010?\" or \"What about Ferrari?\"\n",
    "   - Preserves context when the conversation topic evolves\n",
    "\n",
    "3. **Enhanced answer formatting**:\n",
    "   - Dynamically structures responses based on query type\n",
    "   - Includes relevant statistics and comparative data\n",
    "   - Provides attribution to source facts\n",
    "\n",
    "This design creates a more natural conversational experience while ensuring answers remain grounded in the factual knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XhBW3YvwFrZT"
   },
   "outputs": [],
   "source": [
    "class F1Chatbot:\n",
    "    def __init__(self, retriever):\n",
    "        self.retriever = retriever\n",
    "        self.chat_history = []\n",
    "        # Extract all available variables/columns for flexible querying\n",
    "        self.available_columns = list(winners.columns)\n",
    "        self.available_columns_lower = [col.lower() for col in self.available_columns]\n",
    "        # Store the last query and results for follow-up questions\n",
    "        self.last_query = None\n",
    "        self.last_results = None\n",
    "\n",
    "    def extract_drivers(self, query):\n",
    "        # Simple extraction: look for known driver names in the query\n",
    "        driver_names = winners['forename_f1data'] + ' ' + winners['surname_f1data']\n",
    "        found = []\n",
    "        for name in driver_names.unique():\n",
    "            if isinstance(name, str) and name.lower() in query.lower():\n",
    "                found.append(name)\n",
    "        return list(set(found))\n",
    "\n",
    "    def compare_drivers(self, driver1, driver2):\n",
    "        # Aggregate wins for each driver\n",
    "        d1_wins = winners[\n",
    "            (winners['forename_f1data'] + ' ' + winners['surname_f1data'] == driver1)\n",
    "        ]\n",
    "        d2_wins = winners[\n",
    "            (winners['forename_f1data'] + ' ' + winners['surname_f1data'] == driver2)\n",
    "        ]\n",
    "        \n",
    "        # More comprehensive comparison\n",
    "        d1_first_win = d1_wins.sort_values('year_races').iloc[0] if not d1_wins.empty else None\n",
    "        d2_first_win = d2_wins.sort_values('year_races').iloc[0] if not d2_wins.empty else None\n",
    "        \n",
    "        d1_teams = d1_wins['name_constructors'].unique()\n",
    "        d2_teams = d2_wins['name_constructors'].unique()\n",
    "        \n",
    "        # Head-to-head: races where both participated\n",
    "        races_both = set(d1_wins['name_races']).intersection(set(d2_wins['name_races']))\n",
    "        \n",
    "        answer = (\n",
    "            f\"{driver1} has {len(d1_wins)} wins\"\n",
    "            + (f\" (first in {d1_first_win['year_races']:.0f} at {d1_first_win['name_races']})\" if d1_first_win is not None else \"\") +\n",
    "            f\" driving for {', '.join(d1_teams)}.\\n\" +\n",
    "            f\"{driver2} has {len(d2_wins)} wins\"\n",
    "            + (f\" (first in {d2_first_win['year_races']:.0f} at {d2_first_win['name_races']})\" if d2_first_win is not None else \"\") +\n",
    "            f\" driving for {', '.join(d2_teams)}.\\n\" +\n",
    "            f\"Races both have won: {', '.join(races_both) if races_both else 'None'}.\"\n",
    "        )\n",
    "        return answer\n",
    "\n",
    "    def extract_constructor(self, query):\n",
    "        # Look for known constructor names in the query\n",
    "        constructor_names = winners['name_constructors'].dropna().unique()\n",
    "        found = []\n",
    "        for name in constructor_names:\n",
    "            if isinstance(name, str) and name.lower() in query.lower():\n",
    "                found.append(name)\n",
    "        return list(set(found))\n",
    "\n",
    "    def constructor_wins(self, constructor):\n",
    "        # Aggregate wins for the constructor\n",
    "        c_wins = winners[winners['name_constructors'] == constructor]\n",
    "        if c_wins.empty:\n",
    "            return f\"No wins found for {constructor}.\"\n",
    "            \n",
    "        # Group by year to show progression\n",
    "        wins_by_year = c_wins.groupby('year_races').size()\n",
    "        total_wins = len(c_wins)\n",
    "        \n",
    "        # Get unique drivers for this constructor\n",
    "        drivers = c_wins['forename_f1data'] + ' ' + c_wins['surname_f1data']\n",
    "        unique_drivers = drivers.unique()\n",
    "        \n",
    "        # Get most successful seasons\n",
    "        best_year = wins_by_year.idxmax()\n",
    "        best_year_wins = wins_by_year.max()\n",
    "        \n",
    "        facts = c_wins['fact'].tolist()\n",
    "        answer = (\n",
    "            f\"{constructor} has {total_wins} race wins across {len(wins_by_year)} seasons.\\n\"\n",
    "            f\"Most successful year: {best_year:.0f} with {best_year_wins:.0f} wins.\\n\"\n",
    "            f\"Winning drivers: {', '.join(unique_drivers)}.\\n\\n\"\n",
    "            f\"Recent wins:\\n\" + \"\\n\".join([f\"- {fact}\" for fact in sorted(facts, reverse=True)[:3]])\n",
    "        )\n",
    "        return answer\n",
    "\n",
    "    def get_champion_for_year(self, year):\n",
    "        # Find the driver with the most wins in the given year\n",
    "        year_mask = winners['year_races'] == float(year)\n",
    "        year_winners = winners[year_mask]\n",
    "        if year_winners.empty:\n",
    "            return f\"No race winners found for {year}.\"\n",
    "        # Count wins per driver\n",
    "        driver_names = year_winners['forename_f1data'] + ' ' + year_winners['surname_f1data']\n",
    "        win_counts = driver_names.value_counts()\n",
    "        champion = win_counts.idxmax()\n",
    "        wins = win_counts.max()\n",
    "        \n",
    "        # Calculate total races that year\n",
    "        total_races = len(races[races['year'] == float(year)])\n",
    "        \n",
    "        champion_team = year_winners[\n",
    "            (year_winners['forename_f1data'] + ' ' + year_winners['surname_f1data']) == champion\n",
    "        ]['name_constructors'].mode().iloc[0]\n",
    "        \n",
    "        # Get the constructor champion (most constructor wins)\n",
    "        constructor_wins = year_winners['name_constructors'].value_counts()\n",
    "        constructor_champion = constructor_wins.idxmax()\n",
    "        constructor_win_count = constructor_wins.max()\n",
    "        \n",
    "        answer = (\n",
    "            f\"Formula 1 {year} Season Summary:\\n\\n\"\n",
    "            f\"Driver with most wins: {champion} ({wins} out of {total_races} races, driving for {champion_team}).\\n\"\n",
    "            f\"Constructor with most wins: {constructor_champion} ({constructor_win_count} wins).\\n\\n\"\n",
    "            f\"{champion}'s race wins in {year}:\\n\" +\n",
    "            \"\\n\".join([\n",
    "                f\"- {row['fact']}\"\n",
    "                for _, row in year_winners[\n",
    "                    (year_winners['forename_f1data'] + ' ' + year_winners['surname_f1data']) == champion\n",
    "                ].iterrows()\n",
    "            ])\n",
    "        )\n",
    "        return answer\n",
    "\n",
    "    def extract_column_from_query(self, query):\n",
    "        # Try to match a column/variable from the query\n",
    "        for col, col_lower in zip(self.available_columns, self.available_columns_lower):\n",
    "            if col_lower in query.lower():\n",
    "                return col\n",
    "        # Try to match by keywords (e.g., \"year\", \"driver\", \"constructor\", etc.)\n",
    "        keywords = {\n",
    "            \"year\": \"year_races\",\n",
    "            \"driver\": \"forename_f1data\",\n",
    "            \"constructor\": \"name_constructors\",\n",
    "            \"race\": \"name_races\",\n",
    "            \"circuit\": \"name_races\",\n",
    "            \"nationality\": \"nationality_f1data\",\n",
    "            \"points\": \"points_results\",\n",
    "            \"laps\": \"laps_results\",\n",
    "            \"position\": \"position_results\"\n",
    "        }\n",
    "        for key, col in keywords.items():\n",
    "            if key in query.lower():\n",
    "                return col\n",
    "        return None\n",
    "    \n",
    "    def process_followup_question(self, query):\n",
    "        \"\"\"Handle follow-up questions by using context from previous exchanges\"\"\"\n",
    "        if not self.last_query or not self.last_results:\n",
    "            return None\n",
    "            \n",
    "        # Check if this is a follow-up question\n",
    "        followup_indicators = [\"what about\", \"how about\", \"and what\", \"what of\", \"tell me about\"]\n",
    "        is_followup = any(indicator in query.lower() for indicator in followup_indicators)\n",
    "        \n",
    "        if not is_followup:\n",
    "            return None\n",
    "            \n",
    "        # Extract entities from previous query analysis\n",
    "        if len(self.last_results) > 0 and len(self.last_results[0]) > 2:\n",
    "            prev_analysis = self.last_results[0][2]  # Get the analysis from the first result\n",
    "            \n",
    "            # Look for new entities in the follow-up\n",
    "            new_analysis = self.retriever.analyze_query(query)\n",
    "            \n",
    "            # Merge previous context with new query\n",
    "            combined_query = query\n",
    "            \n",
    "            # If the follow-up doesn't specify a year but previous query did\n",
    "            if not new_analysis['year'] and prev_analysis['year']:\n",
    "                combined_query += f\" in {prev_analysis['year']}\"\n",
    "                \n",
    "            # If the follow-up doesn't specify a circuit but previous query did\n",
    "            if not new_analysis['circuit'] and prev_analysis['circuit']:\n",
    "                if prev_analysis['year']:  # Don't duplicate if already added above\n",
    "                    combined_query += f\" at {prev_analysis['circuit']}\"\n",
    "                else:\n",
    "                    combined_query += f\" at {prev_analysis['circuit']}\"\n",
    "                    \n",
    "            return combined_query\n",
    "        return None\n",
    "\n",
    "    def get_column_values(self, column, filter_query=None, limit=5):\n",
    "        # Optionally filter by a keyword in the query\n",
    "        df = winners\n",
    "        if filter_query:\n",
    "            df = df[df.apply(lambda row: filter_query.lower() in str(row).lower(), axis=1)]\n",
    "        values = df[column].dropna().unique()\n",
    "        return values[:limit]\n",
    "\n",
    "    def chat(self, query, top_k=3):\n",
    "        # Process potential follow-up questions\n",
    "        followup_query = self.process_followup_question(query)\n",
    "        if followup_query:\n",
    "            query = followup_query\n",
    "            \n",
    "        # Detect driver comparison\n",
    "        drivers = self.extract_drivers(query)\n",
    "        if len(drivers) == 2 and any(word in query.lower() for word in [\"compare\", \"vs\", \"versus\", \"against\", \"or\"]):\n",
    "            answer = self.compare_drivers(drivers[0], drivers[1])\n",
    "            self.chat_history.append({\"user\": query})\n",
    "            self.chat_history.append({\"bot\": answer})\n",
    "            print(f\"\\nUser: {query}\")\n",
    "            print(f\"Bot:\\n{answer}\\n\")\n",
    "            return\n",
    "\n",
    "        # Detect constructor win queries\n",
    "        constructors = self.extract_constructor(query)\n",
    "        if constructors and (\"win\" in query.lower() or \"victor\" in query.lower()):\n",
    "            answer = self.constructor_wins(constructors[0])\n",
    "            self.chat_history.append({\"user\": query})\n",
    "            self.chat_history.append({\"bot\": answer})\n",
    "            print(f\"\\nUser: {query}\")\n",
    "            print(f\"Bot:\\n{answer}\\n\")\n",
    "            return\n",
    "\n",
    "        # Detect champion for year queries\n",
    "        import re\n",
    "        match = re.search(r'(?:champion|winner).*?(\\d{4})', query.lower())\n",
    "        if match:\n",
    "            year = match.group(1)\n",
    "            answer = self.get_champion_for_year(year)\n",
    "            self.chat_history.append({\"user\": query})\n",
    "            self.chat_history.append({\"bot\": answer})\n",
    "            print(f\"\\nUser: {query}\")\n",
    "            print(f\"Bot:\\n{answer}\\n\")\n",
    "            return\n",
    "\n",
    "        # Variable extraction\n",
    "        col = self.extract_column_from_query(query)\n",
    "        if col:\n",
    "            values = self.get_column_values(col, filter_query=query)\n",
    "            answer = f\"Sample values for '{col}': {', '.join(map(str, values))}\"\n",
    "            self.chat_history.append({\"user\": query})\n",
    "            self.chat_history.append({\"bot\": answer})\n",
    "            print(f\"\\nUser: {query}\")\n",
    "            print(f\"Bot:\\n{answer}\\n\")\n",
    "            return\n",
    "\n",
    "        # Use the retriever for general questions\n",
    "        self.chat_history.append({\"user\": query})\n",
    "        self.last_query = query\n",
    "        self.last_results = self.retriever.retrieve(query, k=top_k)\n",
    "        \n",
    "        # Format better answers based on query analysis\n",
    "        query_analysis = self.last_results[0][2] if self.last_results else None\n",
    "        \n",
    "        if query_analysis and query_analysis['query_type'] == 'win':\n",
    "            if query_analysis['year'] and query_analysis['circuit']:\n",
    "                answer = f\"Results for the {query_analysis['circuit']} Grand Prix in {query_analysis['year']}:\\n\\n\"\n",
    "            elif query_analysis['circuit']:\n",
    "                answer = f\"Race winners at {query_analysis['circuit']}:\\n\\n\"\n",
    "            elif query_analysis['year']:\n",
    "                answer = f\"Race winners in {query_analysis['year']}:\\n\\n\"\n",
    "            else:\n",
    "                answer = \"Race winners:\\n\\n\"\n",
    "        else:\n",
    "            answer = \"Here's what I found:\\n\\n\"\n",
    "            \n",
    "        # Add the retrieved facts with relevance scores\n",
    "        for i, (fact, score, _) in enumerate(self.last_results):\n",
    "            answer += f\"[{score:.2f}] {fact}\\n\"\n",
    "            \n",
    "        self.chat_history.append({\"bot\": answer})\n",
    "        print(f\"\\nUser: {query}\")\n",
    "        print(f\"Bot:\\n{answer}\\n\")\n",
    "\n",
    "    def show_history(self):\n",
    "        for turn in self.chat_history:\n",
    "            for speaker, text in turn.items():\n",
    "                print(f\"{speaker.capitalize()}: {text}\\n\")\n",
    "\n",
    "f1_chatbot = F1Chatbot(retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E136cSx_F6wy"
   },
   "source": [
    "# Testing Our Formula 1 Knowledge Assistant\n",
    "\n",
    "Let's see the system in action! We'll test it with several question types:\n",
    "\n",
    "1. **Specific race results** - \"Who won Monaco in 2019?\"\n",
    "2. **Follow-up questions** - \"How about Silverstone in 2014?\"\n",
    "3. **Championship queries** - \"Who was champion in 2008?\"\n",
    "4. **Driver comparisons** - \"Compare Hamilton and Vettel\"\n",
    "5. **Constructor performance** - \"How many wins does Ferrari have?\"\n",
    "\n",
    "The system should handle these diverse questions while maintaining context between related queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xcCZxGzlFs6P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: Who won the Monaco Grand Prix in 2019?\n",
      "Bot:\n",
      "Results for the Monaco Grand Prix in 2019:\n",
      "\n",
      "[0.86] In 2019, Lewis Hamilton won the Monaco Grand Prix driving for Mercedes.\n",
      "\n",
      "\n",
      "\n",
      "User: How about Silverstone in 2014?\n",
      "Bot:\n",
      "Here's what I found:\n",
      "\n",
      "[0.66] In 2014, Nico Rosberg won the Austrian Grand Prix driving for Mercedes.\n",
      "[0.65] In 2014, Nico Rosberg won the German Grand Prix driving for Mercedes.\n",
      "[0.65] In 2014, Nico Rosberg won the Australian Grand Prix driving for Mercedes.\n",
      "\n",
      "\n",
      "\n",
      "User: Who was champion in 2008?\n",
      "Bot:\n",
      "Formula 1 2008 Season Summary:\n",
      "\n",
      "Driver with most wins: Felipe Massa (6 out of 18 races, driving for Ferrari).\n",
      "Constructor with most wins: Ferrari (8 wins).\n",
      "\n",
      "Felipe Massa's race wins in 2008:\n",
      "- In 2008, Felipe Massa won the Bahrain Grand Prix driving for Ferrari.\n",
      "- In 2008, Felipe Massa won the Turkish Grand Prix driving for Ferrari.\n",
      "- In 2008, Felipe Massa won the French Grand Prix driving for Ferrari.\n",
      "- In 2008, Felipe Massa won the European Grand Prix driving for Ferrari.\n",
      "- In 2008, Felipe Massa won the Belgian Grand Prix driving for Ferrari.\n",
      "- In 2008, Felipe Massa won the Brazilian Grand Prix driving for Ferrari.\n",
      "\n",
      "\n",
      "User: Compare Lewis Hamilton and Sebastian Vettel\n",
      "Bot:\n",
      "Sebastian Vettel has 53 wins (first in 2008 at Italian Grand Prix) driving for Toro Rosso, Red Bull, Ferrari.\n",
      "Lewis Hamilton has 105 wins (first in 2007 at United States Grand Prix) driving for McLaren, Mercedes.\n",
      "Races both have won: Singapore Grand Prix, Belgian Grand Prix, Bahrain Grand Prix, Chinese Grand Prix, British Grand Prix, Japanese Grand Prix, Turkish Grand Prix, Italian Grand Prix, Malaysian Grand Prix, Abu Dhabi Grand Prix, Spanish Grand Prix, Canadian Grand Prix, Brazilian Grand Prix, Australian Grand Prix, Monaco Grand Prix, German Grand Prix, United States Grand Prix, Hungarian Grand Prix.\n",
      "\n",
      "\n",
      "User: How many wins does Ferrari have?\n",
      "Bot:\n",
      "Ferrari has 249 race wins across 59 seasons.\n",
      "Most successful year: 2002 with 15 wins.\n",
      "Winning drivers: Kimi Räikkönen, Felipe Massa, Michael Schumacher, Rubens Barrichello, Eddie Irvine, Jean Alesi, Gerhard Berger, Alain Prost, Nigel Mansell, Michele Alboreto, Patrick Tambay, René Arnoux, Didier Pironi, Gilles Villeneuve, Jody Scheckter, Carlos Reutemann, Niki Lauda, Clay Regazzoni, Jacky Ickx, Mario Andretti, John Surtees, Ludovico Scarfiotti, Lorenzo Bandini, Wolfgang von Trips, Phil Hill, Giancarlo Baghetti, Tony Brooks, Mike Hawthorn, Peter Collins, Luigi Musso, Juan Fangio, Maurice Trintignant, José Froilán González, Alberto Ascari, Nino Farina, Piero Taruffi, Fernando Alonso, Sebastian Vettel, Charles Leclerc, Carlos Sainz.\n",
      "\n",
      "Recent wins:\n",
      "- In 2024, Charles Leclerc won the United States Grand Prix driving for Ferrari.\n",
      "- In 2024, Charles Leclerc won the Monaco Grand Prix driving for Ferrari.\n",
      "- In 2024, Charles Leclerc won the Italian Grand Prix driving for Ferrari.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test a variety of questions to showcase the enhanced system\n",
    "f1_chatbot.chat(\"Who won the Monaco Grand Prix in 2019?\")\n",
    "f1_chatbot.chat(\"How about Silverstone in 2014?\")\n",
    "f1_chatbot.chat(\"Who was champion in 2008?\")\n",
    "f1_chatbot.chat(\"Compare Lewis Hamilton and Sebastian Vettel\")\n",
    "f1_chatbot.chat(\"How many wins does Ferrari have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced F1 RAG System Architecture\n",
    "\n",
    "This notebook demonstrates a complete Retrieval-Augmented Generation system for Formula 1 knowledge, combining several key technologies:\n",
    "\n",
    "## System Components:\n",
    "\n",
    "### 1. Knowledge Base Construction\n",
    "- **Data sources**: Comprehensive F1 race data (1950-2024)\n",
    "- **Knowledge units**: Structured facts about race wins\n",
    "- **Metadata extraction**: Years, circuits, drivers, constructors\n",
    "\n",
    "### 2. Neural Retrieval Engine\n",
    "- **Embedding model**: Sentence-transformer for semantic encoding\n",
    "- **Vector database**: FAISS for efficient similarity search\n",
    "- **Query analysis**: Intent classification and entity extraction\n",
    "- **Filtering system**: Metadata-based pre-filtering\n",
    "\n",
    "### 3. Answer Generation\n",
    "- **Specialized handlers**: Custom logic for common question types\n",
    "- **Context management**: Support for follow-up questions\n",
    "- **Response formatting**: Structured answers with statistics\n",
    "\n",
    "### 4. User Interface\n",
    "- **Interactive chat**: Real-time question answering\n",
    "- **Example questions**: Quick access to demonstration queries\n",
    "- **Visual styling**: Clean presentation of responses\n",
    "\n",
    "This architecture balances factual accuracy with conversational fluidity, enabling both precise answers to specific questions and more exploratory dialogue about Formula 1 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mroja\\AppData\\Local\\Temp\\ipykernel_37128\\1106752471.py:52: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
      "  input_box.on_submit(lambda _: on_submit({'type': 'submit'}))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612ae81f6c1e44e1a6be0ddcdc61908c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<h2 style='text-align:center'>Formula 1 Knowledge Assistant</h2>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08deccd4c4c4486a9ce0ed98c6141e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Try one of these example questions:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff21265a045c488f9bd6c61d4e5bb256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Who won Monaco in 2019?', layout=Layout(width='auto'), style=ButtonStyle())…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630c5d8f192b45c6bd78c66bedf095df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='Or ask your own question:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c69a3d5aaad4f13a5335bee4a67fa99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Question:', layout=Layout(width='90%'), placeholder='Ask a Formula 1 question...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938e0c1c0113409c84c2ea0ceae4342e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid #ddd', border_left='1px solid #ddd', border_right='1px solid #dd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create a more visually appealing chat interface\n",
    "title = widgets.HTML(value=\"<h2 style='text-align:center'>Formula 1 Knowledge Assistant</h2>\")\n",
    "\n",
    "input_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Ask a Formula 1 question...',\n",
    "    description='Question:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='90%')\n",
    ")\n",
    "\n",
    "# Add some example questions as buttons\n",
    "example_questions = [\n",
    "    \"Who won Monaco in 2019?\",\n",
    "    \"Compare Hamilton and Vettel\",\n",
    "    \"Ferrari wins in 2004\",\n",
    "    \"Who was champion in 2008?\"\n",
    "]\n",
    "\n",
    "buttons = [widgets.Button(description=q, layout=widgets.Layout(width='auto')) for q in example_questions]\n",
    "button_box = widgets.HBox(buttons, layout=widgets.Layout(justify_content='center', padding='10px'))\n",
    "\n",
    "# Create a styled output area with a border\n",
    "output_area = widgets.Output(layout=widgets.Layout(\n",
    "    border='1px solid #ddd',\n",
    "    padding='10px',\n",
    "    width='90%',\n",
    "    height='300px',\n",
    "    overflow_y='auto'\n",
    "))\n",
    "\n",
    "def on_submit(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value' and change['new'] == '':\n",
    "        # Only fetch results when user presses Enter (input_box.value is set to '' after Enter)\n",
    "        return\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        return  # Ignore all other changes\n",
    "    # Only handle when user presses Enter (submit event)\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        f1_chatbot.chat(input_box.value)\n",
    "    input_box.value = ''\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        f1_chatbot.chat(b.description)\n",
    "\n",
    "input_box.on_submit(lambda _: on_submit({'type': 'submit'}))\n",
    "for button in buttons:\n",
    "    button.on_click(on_button_click)\n",
    "\n",
    "# Display all widgets\n",
    "display(title)\n",
    "display(widgets.Label(value=\"Try one of these example questions:\"))\n",
    "display(button_box)\n",
    "display(widgets.Label(value=\"Or ask your own question:\"))\n",
    "display(input_box)\n",
    "display(output_area)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
